{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Tests Cross-Sectional Similarity Matrices\n",
    "This notebook takes in all lab test cross-sectional data and computes the similarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# my functions for cross-sectional similarity\n",
    "from crossSectionSimilarity import *\n",
    "from simMatrix import simMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../data/patientData/\"\n",
    "output_dir = \"../data/simMatrices/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lab tests_cross sect_antibodies.csv',\n",
       " 'lab tests_cross sect_blood.csv',\n",
       " 'lab tests_cross sect_breakdown products.csv',\n",
       " 'lab tests_cross sect_enzymes.csv',\n",
       " 'lab tests_cross sect_hepatitis.csv',\n",
       " 'lab tests_cross sect_other lab.csv',\n",
       " 'lab tests_cross sect_proteins.csv']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(input_dir)\n",
    "files = [file for file in files if re.search(\"lab tests_cross sect\", file)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we remove patients that do not have a lot of data from this analysis\n",
    "def removeLowDataPts(df, column_perc = .5):    \n",
    "    # if number of missing higher then remove\n",
    "    missing_cutoff = math.floor(len(df.columns)*column_perc)\n",
    "    \n",
    "    # extract total count and filter patients\n",
    "    df['total_missing'] = df.isnull().sum(axis=1)\n",
    "    filtered_df = df[df['total_missing'] <= missing_cutoff]\n",
    "    filtered_df.drop(columns = 'total_missing', inplace = True)\n",
    "    \n",
    "    # print stats and return filtered dataframe\n",
    "    print(f\"Original Number of Patients: {len(df)}\")\n",
    "    print(f\"Filtered Number of Patients: {len(filtered_df)}\")\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single run through of the pipeline to generate cosine similarity\n",
    "# these functions will likely be pushed to crossSectionSimilarity \n",
    "def prepData(df, column_perc = .5):\n",
    "    \n",
    "    # filter out patients with low data\n",
    "    filtered_df = removeLowDataPts(df, column_perc)\n",
    "    \n",
    "    # normalize our data (mean = 0, sd = 1)\n",
    "    scaled_df = normalizeDF(filtered_df)\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Similarity Matrices\n",
    "Run the entire process\n",
    "\n",
    "I am aware that this could be made significantly faster, but it does not matter for now. I suspect that I will finish the base analysis and visualization early. At which point, I can improve upon certain areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proteins'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-3e0949fe4cee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cat_files' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    df = pd.read_csv(input_dir + file)\n",
    "    processed_df = prepData(df)\n",
    "    \n",
    "    # initialize our similarity matrix class and patient combos \n",
    "    lab_sim = simMatrix(\"lab tests_\" + re.search(\"_.*_(.*)\\\\.csv$\", file).group(1))\n",
    "    processed_df, col_combos = columnCombos(processed_df)\n",
    "    \n",
    "    # now compute similarity between each patient-patient\n",
    "    for i, col_tuple in enumerate(col_combos):\n",
    "        cosine, cosine_melted = computeCosine(processed_df, col_tuple)\n",
    "        lab_sim.insertRow(cosine_melted)\n",
    "        if any(cosine_melted.duplicated(subset = ['patient_1', 'patient_2'])):\n",
    "            print(\"breaking\")\n",
    "            break\n",
    "            \n",
    "        try:\n",
    "            if i % round(len(col_combos)*.1) ==0:\n",
    "                print(f\"Round {i} of {len(col_combos)}\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # export\n",
    "    print(\"Exporting...\")\n",
    "    lab_sim.export(output_dir)\n",
    "    display(lab_sim.similarities)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
